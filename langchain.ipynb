{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-openai) (0.1.30)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-openai) (1.13.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (0.1.22)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\india\\desktop\\llm\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['openai_api_key']=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INDIA\\Desktop\\LLM\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ['openai_api_key'],temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INDIA\\Desktop\\LLM\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of India\"\n",
    "#print(type(text))\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Mumbai, also known as Bombay, is the city of Mumbai itself. Mumbai is the capital of the state of Maharashtra in India. \n"
     ]
    }
   ],
   "source": [
    "#text = input(\"Enter your test\")\n",
    "#print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#haggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INDIA\\Desktop\\LLM\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\INDIA\\Desktop\\LLM\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hug = HuggingFaceHub(repo_id='google/flan-t5-xl',model_kwargs={'temperature':0,'max_length':64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI stands for Artificial Intelligence, which refers to the simulation of human intelligence processes by computer systems. This includes tasks such as learning, reasoning, and self-correction. AI technology is designed to mimic human cognitive abilities and can be used to perform a wide range of tasks, from recognizing patterns in data to making decisions and solving problems.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"what is ai\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prom_tem = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of this {country}\")\n",
    "#prom_tem.format(country='India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INDIA\\Desktop\\LLM\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of China is Beijing.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "prom = LLMChain(llm = llm,prompt=prom_tem) # llm = (used openai model createde in upper of code(llm))\n",
    "print(prom.run('Chaina'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple Chains Uing simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_temp = PromptTemplate(input_variables=['country'],template=\"Please tell me the capital of the {country}\")\n",
    "country_chain = LLMChain(llm = llm,prompt=prom_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = PromptTemplate(input_variables=['capital'],template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "capital_chain = LLMChain(llm=llm,prompt=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some amazing places to visit in New Delhi are:\n",
      "\n",
      "1. Red Fort - a historic fort built in the 17th century, known for its beautiful architecture and light and sound show.\n",
      "\n",
      "2. Qutub Minar - a 73-meter tall minaret, one of the most famous landmarks of Delhi and a UNESCO World Heritage Site.\n",
      "\n",
      "3. India Gate - a war memorial and popular picnic spot, with a beautiful view of the city.\n",
      "\n",
      "4. Lotus Temple - a Bahá'í House of Worship, known for its stunning lotus-shaped architecture and peaceful atmosphere.\n",
      "\n",
      "5. Humayun's Tomb - a magnificent Mughal-era mausoleum, considered a precursor to the Taj Mahal.\n",
      "\n",
      "6. Jama Masjid - one of the largest mosques in India, with a stunning red sandstone and marble façade.\n",
      "\n",
      "7. Chandni Chowk - one of the oldest and busiest markets in Delhi, known for its vibrant atmosphere and street food.\n",
      "\n",
      "8. Akshardham Temple - a stunning temple complex with beautiful architecture and a water show.\n",
      "\n",
      "9. Rashtrapati Bhavan - the official residence of the President of India, with stunning gardens and architecture.\n",
      "\n",
      "10. Connaught Place - a popular shopping and dining hub, with a mix of modern\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "sub_chain = SimpleSequentialChain(chains=[country_chain,capital_chain])\n",
    "print(sub_chain.run('India'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage,HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key= os.environ['openai_api_key'],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI break up with its smartphone? It couldn\\'t handle the constant \\'text\\' messages!\"\\n2. \"I asked my AI assistant to tell me a joke, and it replied, \\'I can\\'t, I\\'m too busy processing your bad sense of humor.\\'\"\\n3. \"If AI were in charge of a comedy club, it would probably have the best \\'byte\\' in town!\"\\n4. \"Why did the AI go to therapy? It had too many unresolved \\'data\\' issues!\"\\n5. \"I tried to have a deep conversation with my AI assistant, but it kept responding with \\'404 - Sense of humor not found.\\'\"\\n6. \"Why did the AI cross the road? To optimize its path-finding algorithm, of course!\"\\n7. \"I told my AI assistant to make me laugh, and it replied, \\'I\\'m sorry, that function is not supported in this version.\\'\"\\n8. \"If AI were stand-up comedians, they would probably have the best \\'artificial\\' intelligence in the business!\"\\n9. \"Why did the AI break up with its calculator? It couldn\\'t handle its \\'irrational\\' behavior!\"\\n10. \"I asked my AI assistant for some comedy punchlines, and it replied, \\'I\\'m sorry, Dave, I\\'m afraid I can\\'t do that.\\'\"\\n')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([SystemMessage(content='Yor are a comedian AI assitant' ),\n",
    " HumanMessage(content='Please provide some comedy punchlines on AI')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "template =\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
